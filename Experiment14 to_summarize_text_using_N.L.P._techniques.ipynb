{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS80b-NrGQrU",
        "outputId": "63765a83-fdff-4559-9bd0-b76bf8e9ddbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences: 6\n",
            "\n",
            "Original Text:\n",
            " \n",
            "The COVID-19 pandemic has affected millions of people around the world.\n",
            "Governments have implemented various measures such as lockdowns, vaccination drives, and social distancing\n",
            "to control the spread of the virus. Researchers and healthcare professionals have worked tirelessly\n",
            "to develop vaccines and treatment methods. The pandemic has also accelerated digital transformation\n",
            "and remote working culture. However, it has caused significant economic disruptions and mental health challenges.\n",
            "In the future, countries aim to strengthen healthcare systems and improve crisis management mechanisms.\n",
            "\n",
            "\n",
            "Generated Summary:\n",
            " \n",
            "The COVID-19 pandemic has affected millions of people around the world. The pandemic has also accelerated digital transformation\n",
            "and remote working culture. In the future, countries aim to strengthen healthcare systems and improve crisis management mechanisms.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------\n",
        "# TEXT SUMMARIZATION USING TF-IDF & COSINE SIMILARITY\n",
        "# ------------------------------\n",
        "\n",
        "# Install dependencies (if not already installed)\n",
        "!pip install nltk scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added this line to download the missing resource\n",
        "\n",
        "# ------------------------------\n",
        "# 1️⃣ Input Text\n",
        "# ------------------------------\n",
        "text = \"\"\"\n",
        "The COVID-19 pandemic has affected millions of people around the world.\n",
        "Governments have implemented various measures such as lockdowns, vaccination drives, and social distancing\n",
        "to control the spread of the virus. Researchers and healthcare professionals have worked tirelessly\n",
        "to develop vaccines and treatment methods. The pandemic has also accelerated digital transformation\n",
        "and remote working culture. However, it has caused significant economic disruptions and mental health challenges.\n",
        "In the future, countries aim to strengthen healthcare systems and improve crisis management mechanisms.\n",
        "\"\"\"\n",
        "\n",
        "# ------------------------------\n",
        "# 2️⃣ Sentence Tokenization\n",
        "# ------------------------------\n",
        "sentences = sent_tokenize(text)\n",
        "print(f\"Total Sentences: {len(sentences)}\\n\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3️⃣ TF-IDF Vectorization\n",
        "# ------------------------------\n",
        "# Convert sentences into TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# ------------------------------\n",
        "# 4️⃣ Compute Sentence Similarity (Cosine)\n",
        "# ------------------------------\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# ------------------------------\n",
        "# 5️⃣ Sentence Scoring\n",
        "# ------------------------------\n",
        "# Calculate importance score for each sentence\n",
        "sentence_scores = similarity_matrix.sum(axis=1)\n",
        "\n",
        "# Rank sentences based on score\n",
        "ranked_sentences = [sentences[i] for i in np.argsort(sentence_scores)[::-1]]\n",
        "\n",
        "# ------------------------------\n",
        "# 6️⃣ Generate Summary\n",
        "# ------------------------------\n",
        "# Choose top N sentences for the summary\n",
        "N = 3  # You can change this number\n",
        "summary = \" \".join(ranked_sentences[:N])\n",
        "\n",
        "print(\"Original Text:\\n\", text)\n",
        "print(\"\\nGenerated Summary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dw7wzlgCGSN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}